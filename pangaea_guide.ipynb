{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7Qtp0JCAJuC"
      },
      "source": [
        "\n",
        "# PANGAEA Bench Hands-on Tutorial\n",
        "\n",
        "## ğŸŒŸ What This Colab File Provides\n",
        "This notebook serves as a quickstart guide for setting up and running experiments with PANGAEA's benchmarking framework. It includes:\n",
        "1. **Environment Setup**: Clone the repository and install required dependencies.\n",
        "2. **Data Loading**: Instructions on how to load datasets for geospatial tasks.\n",
        "3. **Model Selection and Training**: Select a model and configure a pipeline for training.\n",
        "4. **Running the Pipeline**: Complete an end-to-end experiment for evaluation.\n",
        "\n",
        "Follow along to get started!\n",
        "\n",
        "But before save your own copy (_File->Save a copy in Drive_) and\n",
        "CHANGE THE RUNTIME TYPE to GPU\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Designed by Valerio Marsocci\n",
        "\n",
        "### Got questions or innovative ideas? Drop a message at Valerio.Marsocci@esa.int \n",
        "\n",
        "---\n",
        "\n",
        "## Let's Start! ğŸ›°ï¸\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa3w8qf3AsaG"
      },
      "source": [
        "## Clone the Repository\n",
        "\n",
        "First clone the PANGAEA repository and navigate to the directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzOgNYKRqpKw",
        "outputId": "3ab4a0f1-b462-4aaa-8091-f54ec216277e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pangaea-bench'...\n",
            "remote: Enumerating objects: 4743, done.\u001b[K\n",
            "remote: Counting objects: 100% (1370/1370), done.\u001b[K\n",
            "remote: Compressing objects: 100% (437/437), done.\u001b[K\n",
            "remote: Total 4743 (delta 1141), reused 933 (delta 933), pack-reused 3373 (from 2)\u001b[K\n",
            "Receiving objects: 100% (4743/4743), 3.55 MiB | 19.12 MiB/s, done.\n",
            "Resolving deltas: 100% (3220/3220), done.\n",
            "/content/pangaea-bench\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/VMarsocci/pangaea-bench.git\n",
        "%cd pangaea-bench"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp2KeCGaA_-T"
      },
      "source": [
        "## Install Dependencies\n",
        "   We will set up the environment using pip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yM2nmXH1BCsh",
        "outputId": "cebe8e8e-65e7-453a-fea7-85167d1d3e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.0.1)\n",
            "Collecting rasterio (from -r requirements.txt (line 4))\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (11.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2025.6.11)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.0.17)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.8.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (4.11.0.86)\n",
            "Collecting rioxarray (from -r requirements.txt (line 13))\n",
            "  Downloading rioxarray-0.19.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (5.2.0)\n",
            "Collecting ptflops (from -r requirements.txt (line 15))\n",
            "  Downloading ptflops-0.7.4-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.19.0)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (2.3.0)\n",
            "Collecting pyDataverse (from -r requirements.txt (line 18))\n",
            "  Downloading pydataverse-0.3.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (8.3.5)\n",
            "Collecting yacs (from -r requirements.txt (line 20))\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.21.0)\n",
            "Collecting hydra-core (from -r requirements.txt (line 22))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas->-r requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->-r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->-r requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->-r requirements.txt (line 3)) (2.1.1)\n",
            "Collecting affine (from rasterio->-r requirements.txt (line 4))\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 4)) (2025.7.9)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 4)) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio->-r requirements.txt (line 4))\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio->-r requirements.txt (line 4))\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio->-r requirements.txt (line 4)) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 10)) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 10)) (0.33.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 10)) (0.5.3)\n",
            "Requirement already satisfied: xarray>=2024.7.0 in /usr/local/lib/python3.11/dist-packages (from rioxarray->-r requirements.txt (line 13)) (2025.3.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 14)) (4.13.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 14)) (2.32.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r requirements.txt (line 16)) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r requirements.txt (line 16)) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r requirements.txt (line 16)) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r requirements.txt (line 16)) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->-r requirements.txt (line 16)) (1.7.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 17)) (4.9.3)\n",
            "Collecting httpx<0.28.0,>=0.27.0 (from pyDataverse->-r requirements.txt (line 18))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from pyDataverse->-r requirements.txt (line 18)) (4.24.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements.txt (line 19)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements.txt (line 19)) (1.6.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 21)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 21)) (4.3.8)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 21)) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 21)) (2.32.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 21)) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->-r requirements.txt (line 16)) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->-r requirements.txt (line 16)) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r requirements.txt (line 16)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r requirements.txt (line 16)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r requirements.txt (line 16)) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->pyDataverse->-r requirements.txt (line 18)) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->pyDataverse->-r requirements.txt (line 18)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->pyDataverse->-r requirements.txt (line 18)) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->pyDataverse->-r requirements.txt (line 18)) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->pyDataverse->-r requirements.txt (line 18)) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.21.1->pyDataverse->-r requirements.txt (line 18)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.21.1->pyDataverse->-r requirements.txt (line 18)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.21.1->pyDataverse->-r requirements.txt (line 18)) (0.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->geopandas->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 21)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 21)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 21)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 14)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 14)) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 14)) (2.7)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 10)) (1.1.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 14)) (1.7.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 21)) (5.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage->-r requirements.txt (line 16)) (0.6.1)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rioxarray-0.19.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ptflops-0.7.4-py3-none-any.whl (19 kB)\n",
            "Downloading pydataverse-0.3.4-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: yacs, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, cligj, click-plugins, affine, rasterio, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, httpx, nvidia-cusolver-cu12, rioxarray, pyDataverse, ptflops\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-genai 1.25.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 httpx-0.27.2 hydra-core-1.3.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ptflops-0.7.4 pyDataverse-0.3.4 rasterio-1.4.3 rioxarray-0.19.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NUYtJIf9yaI",
        "outputId": "d9ed43e1-10d4-4eee-89f0-cca101483cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting imagecodecs\n",
            "  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagecodecs) (2.0.2)\n",
            "Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imagecodecs\n",
            "Successfully installed imagecodecs-2025.3.30\n"
          ]
        }
      ],
      "source": [
        "!pip install imagecodecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmHYVBZJBi1r",
        "outputId": "6ba75402-385a-4a40-b79a-8429f6eb7984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'pangaea-bench'\n",
            "/content/pangaea-bench\n",
            "Obtaining file:///content/pangaea-bench\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: pangaea\n",
            "  Running setup.py develop for pangaea\n",
            "Successfully installed pangaea-1.0.0\n"
          ]
        }
      ],
      "source": [
        "# Probably you had to restart the runtime to correctly install packages, so let's change path again\n",
        "%cd pangaea-bench\n",
        "# Install the repository as a development package\n",
        "!pip install --no-build-isolation --no-deps -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TH206tNGKo1"
      },
      "source": [
        "## Adding a new dataset\n",
        "\n",
        "We will implement a *toy* version of [FLAIR dataset](https://arxiv.org/pdf/2211.12979). The data are already stored on [Google Drive](https://drive.google.com/drive/folders/1uAJ7-m7stdeGenKQMLkRaEkKhR4uVbzU?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtuth9RFyy7R",
        "outputId": "7e3656df-4a24-4911-eb0e-820baaf626de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1U8woGV2YlzeGSZKN2BPdz4gAySkEsmiJ\n",
            "From (redirected): https://drive.google.com/uc?id=1U8woGV2YlzeGSZKN2BPdz4gAySkEsmiJ&confirm=t&uuid=b73e95b2-1bf9-4005-a54b-067be6dfdc4d\n",
            "To: /content/pangaea-bench/toyFLAIR.zip\n",
            "100% 226M/226M [00:02<00:00, 92.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "#let's download the dataset from this link https://drive.google.com/file/d/1U8woGV2YlzeGSZKN2BPdz4gAySkEsmiJ/view?usp=drive_link\n",
        "\n",
        "!gdown --id 1U8woGV2YlzeGSZKN2BPdz4gAySkEsmiJ --output toyFLAIR.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPi5xf2k1F7d",
        "outputId": "dc832782-06a1-44c2-ec25-63c9c7eec8a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  toyFLAIR.zip\n",
            "   creating: toyFLAIR/\n",
            "   creating: toyFLAIR/test/\n",
            "   creating: toyFLAIR/test/images/\n",
            "  inflating: toyFLAIR/test/images/IMG_061946.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_062207.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_062393.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_062524.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_062871.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_063104.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_063120.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_063366.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_063620.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_063812.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_064026.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_064027.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_064234.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_064890.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_065011.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_065120.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_065229.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_065275.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_066278.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_066772.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_067094.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_067163.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_067195.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_067998.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_069067.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_069248.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_069274.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_070457.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_070770.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_071026.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_071100.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_071586.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_071824.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_071940.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_072628.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_072737.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_073700.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_073879.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_074054.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_074756.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_075191.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_076041.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_076083.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_076193.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_076201.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_076311.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_076459.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_076632.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_076686.tif  \n",
            "  inflating: toyFLAIR/test/images/IMG_076821.tif  \n",
            "   creating: toyFLAIR/test/masks/\n",
            "  inflating: toyFLAIR/test/masks/MSK_061946.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_062207.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_062393.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_062524.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_062871.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_063104.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_063120.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_063366.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_063620.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_063812.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_064026.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_064027.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_064234.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_064890.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_065011.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_065120.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_065229.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_065275.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_066278.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_066772.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_067094.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_067163.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_067195.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_067998.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_069067.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_069248.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_069274.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_070457.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_070770.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_071026.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_071100.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_071586.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_071824.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_071940.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_072628.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_072737.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_073700.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_073879.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_074054.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_074756.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_075191.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_076041.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_076083.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_076193.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_076201.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_076311.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_076459.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_076632.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_076686.tif  \n",
            "  inflating: toyFLAIR/test/masks/MSK_076821.tif  \n",
            "   creating: toyFLAIR/train/\n",
            "   creating: toyFLAIR/train/images/\n",
            "  inflating: toyFLAIR/train/images/IMG_001981.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_002126.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_002993.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_003020.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_003022.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_003388.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_003690.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_003895.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_004142.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_004192.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_004753.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_004991.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_005183.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_005226.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_005273.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_005339.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_005484.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_005625.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_005659.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_005855.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_006235.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_006390.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_007050.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_007292.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_007296.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_008242.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_008243.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_008547.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_008878.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_008921.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_009344.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_009442.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_009517.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_009542.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_009608.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_009679.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_009774.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_009807.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_012425.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_012527.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_012628.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_012777.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_013356.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_013619.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_013958.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_014757.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_015082.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_015301.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_015771.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_015775.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_016443.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_016736.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_016981.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_017069.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_019824.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_021680.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_022249.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_022673.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_023195.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_024459.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_024602.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_024969.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_024985.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_025081.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_025215.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_025559.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_025595.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_026246.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_026552.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_027675.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_028081.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_028233.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_028685.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_028711.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_028913.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_029084.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_029476.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_030151.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_031933.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_032260.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_032884.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_032918.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_033021.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_033565.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_034267.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_034736.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_034939.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_035091.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_036018.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_036648.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_036875.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_037906.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_040440.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_040509.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_040742.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_040936.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_041182.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_041352.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_041421.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_041457.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_041942.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_042089.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_042561.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_042783.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_042957.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_043112.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_048618.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_048654.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_049024.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_049203.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_049784.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_049920.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_050072.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_050075.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_050078.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_050345.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_050546.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_050775.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_050857.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_050959.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_051073.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_051095.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_051111.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_051315.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_051322.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_051446.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_051784.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_051902.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_052457.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_052903.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_053212.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_053327.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_053371.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_053413.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_053690.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_053836.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_053923.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_054213.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_054215.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_054413.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_055210.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_055265.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_055266.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_055269.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_056260.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_057542.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_057617.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_057725.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_058980.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_059050.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_059477.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_060127.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_060181.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_060258.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_060866.tif  \n",
            "  inflating: toyFLAIR/train/images/IMG_061047.tif  \n",
            "   creating: toyFLAIR/train/masks/\n",
            "  inflating: toyFLAIR/train/masks/MSK_001981.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_002126.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_002993.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_003020.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_003022.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_003388.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_003690.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_003895.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_004142.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_004192.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_004753.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_004991.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_005183.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_005226.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_005273.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_005339.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_005484.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_005625.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_005659.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_005855.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_006235.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_006390.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_007050.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_007292.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_007296.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_008242.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_008243.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_008547.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_008878.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_008921.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_009344.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_009442.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_009517.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_009542.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_009608.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_009679.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_009774.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_009807.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_012425.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_012527.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_012628.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_012777.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_013356.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_013619.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_013958.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_014757.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_015082.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_015301.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_015771.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_015775.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_016443.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_016736.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_016981.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_017069.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_019824.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_021680.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_022249.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_022673.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_023195.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_024459.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_024602.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_024969.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_024985.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_025081.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_025215.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_025559.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_025595.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_026246.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_026552.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_027675.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_028081.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_028233.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_028685.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_028711.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_028913.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_029084.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_029476.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_030151.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_031933.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_032260.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_032884.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_032918.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_033021.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_033565.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_034267.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_034736.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_034939.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_035091.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_036018.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_036648.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_036875.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_037906.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_040440.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_040509.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_040742.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_040936.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_041182.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_041352.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_041421.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_041457.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_041942.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_042089.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_042561.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_042783.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_042957.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_043112.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_048618.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_048654.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_049024.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_049203.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_049784.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_049920.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_050072.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_050075.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_050078.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_050345.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_050546.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_050775.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_050857.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_050959.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_051073.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_051095.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_051111.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_051315.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_051322.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_051446.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_051784.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_051902.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_052457.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_052903.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_053212.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_053327.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_053371.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_053413.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_053690.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_053836.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_053923.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_054213.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_054215.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_054413.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_055210.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_055265.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_055266.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_055269.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_056260.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_057542.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_057617.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_057725.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_058980.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_059050.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_059477.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_060127.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_060181.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_060258.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_060866.tif  \n",
            "  inflating: toyFLAIR/train/masks/MSK_061047.tif  \n",
            "   creating: toyFLAIR/val/\n",
            "   creating: toyFLAIR/val/images/\n",
            "  inflating: toyFLAIR/val/images/IMG_000717.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_000734.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_000883.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_001119.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_001331.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_011121.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_011282.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_011339.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_011617.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_011666.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_011799.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_011942.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_017880.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_018933.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_019010.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_019013.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_019213.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_020203.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_020231.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_020484.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_020838.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_021419.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_021429.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_021543.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_039109.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_039118.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_043502.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_043548.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_044312.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_044933.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_045066.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_045123.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_045700.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_045881.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_045898.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_046331.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_046678.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_046726.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_046823.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_047762.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_047958.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_048266.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_048326.tif  \n",
            "  inflating: toyFLAIR/val/images/IMG_048455.tif  \n",
            "   creating: toyFLAIR/val/masks/\n",
            "  inflating: toyFLAIR/val/masks/MSK_000717.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_000734.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_000883.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_001119.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_001331.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_011121.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_011282.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_011339.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_011617.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_011666.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_011799.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_011942.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_017880.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_018933.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_019010.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_019013.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_019213.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_020203.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_020231.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_020484.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_020838.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_021419.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_021429.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_021543.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_039109.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_039118.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_043502.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_043548.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_044312.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_044933.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_045066.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_045123.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_045700.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_045881.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_045898.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_046331.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_046678.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_046726.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_046823.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_047762.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_047958.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_048266.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_048326.tif  \n",
            "  inflating: toyFLAIR/val/masks/MSK_048455.tif  \n"
          ]
        }
      ],
      "source": [
        "!unzip toyFLAIR.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZZlJaxMcnkc"
      },
      "source": [
        "The data structure is as follows:\n",
        "```\n",
        "toyFLAIR/\n",
        "â”œâ”€â”€ train/\n",
        "â”‚   â”œâ”€â”€ images/\n",
        "â”‚   â””â”€â”€ labels/\n",
        "â”œâ”€â”€ val/\n",
        "â”‚   â”œâ”€â”€ images/\n",
        "â”‚   â””â”€â”€ labels/\n",
        "â””â”€â”€ test/\n",
        "    â”œâ”€â”€ images/\n",
        "    â””â”€â”€ labels/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buZjyPU1c4Xf"
      },
      "source": [
        "How to add a new dataset? Follow [these instructions](https://github.com/VMarsocci/pangaea-bench/blob/main/.github/CONTRIBUTING.md#adding-a-new-downstream-dataset)\n",
        "\n",
        "TL;DR:\n",
        "you need to create two files:\n",
        " - a _config.yaml_ file and put it in _configs/dataset_\n",
        " - a _dataset.py_ file and put in _pangaea/dataset_\n",
        "\n",
        "\n",
        "Follow this code for the _dataset.py_ file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO1v57XrCkv1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from pangaea.datasets.base import RawGeoFMDataset\n",
        "\n",
        "class MyDataset(RawGeoFMDataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        split: str,\n",
        "        dataset_name: str,\n",
        "        multi_modal: bool,\n",
        "        multi_temporal: int,\n",
        "        root_path: str,\n",
        "        classes: list,\n",
        "        num_classes: int,\n",
        "        ignore_index: int,\n",
        "        img_size: int,\n",
        "        bands: dict[str, list[str]],\n",
        "        distribution: list[int],\n",
        "        data_mean: dict[str, list[str]],\n",
        "        data_std: dict[str, list[str]],\n",
        "        data_min: dict[str, list[str]],\n",
        "        data_max: dict[str, list[str]],\n",
        "        download_url: str,\n",
        "        auto_download: bool,\n",
        "        temp: int, #newly added parameter\n",
        "    ):\n",
        "        super(MyDataset, self).__init__(\n",
        "            split=split,\n",
        "            dataset_name=dataset_name,\n",
        "            multi_modal=multi_modal,\n",
        "            multi_temporal=multi_temporal,\n",
        "            root_path=root_path,\n",
        "            classes=classes,\n",
        "            num_classes=num_classes,\n",
        "            ignore_index=ignore_index,\n",
        "            img_size=img_size,\n",
        "            bands=bands,\n",
        "            distribution=distribution,\n",
        "            data_mean=data_mean,\n",
        "            data_std=data_std,\n",
        "            data_min=data_min,\n",
        "            data_max=data_max,\n",
        "            download_url=download_url,\n",
        "            auto_download=auto_download,\n",
        "        )\n",
        "\n",
        "        self.temp = temp #newly added parameter\n",
        "        # Initialize file lists or data structures here\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of samples\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Returns the i-th item of the dataset.\n",
        "\n",
        "        Args:\n",
        "            i (int): index of the item\n",
        "\n",
        "        Raises:\n",
        "            NotImplementedError: raise if the method is not implemented\n",
        "\n",
        "        Returns:\n",
        "            dict[str, torch.Tensor | dict[str, torch.Tensor]]: output dictionary follwing the format\n",
        "            {\"image\":\n",
        "                {\n",
        "                \"optical\": torch.Tensor of shape (C T H W) (where T=1 if single-temporal dataset),\n",
        "                    \"sar\": torch.Tensor of shape (C T H W) (where T=1 if single-temporal dataset),\n",
        "                    },\n",
        "            \"target\": torch.Tensor of shape (H W) of type torch.int64 for segmentation, torch.float for\n",
        "            regression datasets.,\n",
        "                \"metadata\": dict}.\n",
        "        \"\"\"\n",
        "        # Load your data and labels here\n",
        "        image = ...  # Load image\n",
        "        target = ...  # Load target label or mask\n",
        "\n",
        "        # Convert to tensors\n",
        "        image = torch.tensor(image, dtype=torch.float32)\n",
        "        target = torch.tensor(target, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            'image': {'optical': image},\n",
        "            'target': target,\n",
        "            'metadata': {}\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def download(self, silent=False):\n",
        "        # Implement if your dataset requires downloading\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3auRQPRdwrf"
      },
      "source": [
        "Some other practical hints/reccomendetions:\n",
        " - name your _dataset_ file: ***toy_flair.py*** and put it in _configs/dataset_\n",
        " - name your _config_ file: ***toyflair.yaml*** and put it in _pangaea/datasets_\n",
        " - HINT! Get inspired by FiveBillionPixels files to follow the structure of the files. The data structure is the same!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V0o-FbAfQB1"
      },
      "source": [
        "Now you are ready to run the code on your newly added dataset. Run the following command line!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DBPvJs-AfXlz"
      },
      "outputs": [],
      "source": [
        "# Name of the config referring to the dataset\n",
        "# Model: RemoteCLIP (lightweight, checkpoints downloaded automatically)\n",
        "# Decoder: UperNet\n",
        "\n",
        "!torchrun --nnodes=1 --nproc_per_node=1 pangaea/run.py \\\n",
        "  --config-name=train \\\n",
        "  dataset=toyflair \\\n",
        "  encoder=remoteclip \\\n",
        "  decoder=seg_upernet \\\n",
        "  preprocessing=seg_default \\\n",
        "  criterion=cross_entropy \\\n",
        "  task=segmentation \\\n",
        "  use_wandb=True \\\n",
        "  task.trainer.n_epochs=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8XzcWKDu_xt"
      },
      "outputs": [],
      "source": [
        "!torchrun pangaea/run.py --config-name=test ckpt_dir=/insert/your/results/directory #e.g. ckpt_dir=/content/pangaea-bench/20250716_143827_8ec411_remoteclip_seg_upernet_toyflair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wYI9FqnCx-g"
      },
      "outputs": [],
      "source": [
        "# Name of the config referring to the dataset\n",
        "# Model: RemoteCLIP (lightweight, checkpoints downloaded automatically)\n",
        "# Decoder: UperNet\n",
        "# let's train it for longer!\n",
        "\n",
        "!torchrun --nnodes=1 --nproc_per_node=1 pangaea/run.py \\\n",
        "  --config-name=train \\\n",
        "  dataset=toyflair \\\n",
        "  encoder=remoteclip \\\n",
        "  decoder=seg_upernet \\\n",
        "  preprocessing=seg_default \\\n",
        "  criterion=cross_entropy \\\n",
        "  task=segmentation \\\n",
        "  use_wandb=True \\\n",
        "  task.trainer.n_epochs=40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM-S-np2vAYd"
      },
      "outputs": [],
      "source": [
        "!torchrun pangaea/run.py --config-name=test ckpt_dir=/insert/your/results/directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3S_BdL0D3wG"
      },
      "outputs": [],
      "source": [
        "# Name of the config referring to the dataset\n",
        "# Model: RemoteCLIP (lightweight, checkpoints downloaded automatically)\n",
        "# Decoder: UperNet\n",
        "# but let's switch the loss to DICE loss!\n",
        "\n",
        "!torchrun --nnodes=1 --nproc_per_node=1 pangaea/run.py \\\n",
        "  --config-name=train \\\n",
        "  dataset=toyflair \\\n",
        "  encoder=remoteclip \\\n",
        "  decoder=seg_upernet \\\n",
        "  preprocessing=seg_default \\\n",
        "  criterion=dice \\\n",
        "  task=segmentation \\\n",
        "  use_wandb=True \\\n",
        "  task.trainer.n_epochs=40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0HSOG-KFe7m"
      },
      "outputs": [],
      "source": [
        "!torchrun pangaea/run.py --config-name=test ckpt_dir=/insert/your/results/directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYm9yuFoli4K"
      },
      "source": [
        "## Adding a new model\n",
        "\n",
        "We will implement [FG-MAE](https://github.com/zhu-xlab/FGMAE). The checkpoints (ViT-S) are already stored on [Google Drive](https://drive.google.com/file/d/14EJgdtyIJ9Gk8A4ritoF6JPkeCZmCeS_/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P80ELbV8-D6O",
        "outputId": "e01de134-46d4-45be-fabd-d9a2e4340156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=14EJgdtyIJ9Gk8A4ritoF6JPkeCZmCeS_\n",
            "From (redirected): https://drive.google.com/uc?id=14EJgdtyIJ9Gk8A4ritoF6JPkeCZmCeS_&confirm=t&uuid=6b3f0b2a-f0c6-4fd0-96ff-df1293b36116\n",
            "To: /content/pangaea-bench/pretrained_models/B13_vits16_fgmae_ep99.pth\n",
            "100% 585M/585M [00:11<00:00, 52.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "#let's download the dataset from this link https://drive.google.com/file/d/14EJgdtyIJ9Gk8A4ritoF6JPkeCZmCeS_/view?usp=drive_link\n",
        "\n",
        "!gdown --id 14EJgdtyIJ9Gk8A4ritoF6JPkeCZmCeS_ --output pretrained_models/B13_vits16_fgmae_ep99.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eb_no5-qgfg"
      },
      "source": [
        "How to add a new model? Follow [these instructions](https://github.com/VMarsocci/pangaea-bench/blob/main/.github/CONTRIBUTING.md#adding-a-new-geospatial-foundation-model)\n",
        "\n",
        "TL;DR:\n",
        "you need to create two files:\n",
        " - a _config.yaml_ file and put it in _configs/encoder_\n",
        " - a _model.py_ file and put in _pangaea/encoders_\n",
        "\n",
        "\n",
        "Follow this code for the _model.py_ file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY5ymw1HliT8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "from pangaea.encoders.base import Encoder\n",
        "\n",
        "class MyModel(Encoder):\n",
        "    def __init__(\n",
        "        self,\n",
        "        encoder_weights: str | Path,\n",
        "        input_size: int,\n",
        "        input_bands: dict[str, list[str]],\n",
        "        output_layers: int | list[int],\n",
        "        in_chans: int,              #newly added parameter\n",
        "    ) -> None:\n",
        "        super().__init__(\n",
        "            model_name=\"my_model_name\",\n",
        "            encoder_weights=encoder_weights,\n",
        "            input_bands=input_bands,\n",
        "            input_size=input_size,\n",
        "            embed_dim=768,        # my_model_embed_dim, fixed parameters\n",
        "            output_dim=768,       # my_model_output_dim, fixed parameters\n",
        "            multi_temporal=False, # wether support multi-temporal, fixed parametersfixed parameters\n",
        "            multi_temporal_ouput=False, # wether the output of the model has a temporal dimension\n",
        "        )\n",
        "\n",
        "        self.in_chans = in_chans    #newly added parameter\n",
        "\n",
        "        # Initialize your model architecture here\n",
        "        # For example:\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(in_chans, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            # Add more layers as needed\n",
        "        )\n",
        "        # Specify output layers if applicable\n",
        "\n",
        "    def load_encoder_weights(self, pretrained_path: str) -> None:\n",
        "        # Load pretrained weights\n",
        "        state_dict = torch.load(pretrained_path, map_location='cpu')\n",
        "        self.load_state_dict(state_dict, strict=False)\n",
        "        print(f\"Loaded encoder weights from {pretrained_path}\")\n",
        "\n",
        "    def forward(self, x: dict[str, torch.Tensor]) -> list[torch.Tensor]:\n",
        "        \"\"\"Foward pass of the encoder.\n",
        "\n",
        "        Args:\n",
        "            x (dict[str, torch.Tensor]): encoder's input structured as a dictionary:\n",
        "            x = {modality1: tensor1, modality2: tensor2, ...}, e.g. x = {\"optical\": tensor1, \"sar\": tensor2}.\n",
        "            If the encoder is multi-temporal (self.multi_temporal==True), input tensor shape is (B C T H W) with C the\n",
        "            number of bands required by the encoder for the given modality and T the number of time steps. If the\n",
        "            encoder is not multi-temporal, input tensor shape is (B C H W) with C the number of bands required by the\n",
        "            encoder for the given modality.\n",
        "\n",
        "        Returns:\n",
        "            list[torch.Tensor]: list of the embeddings for each modality. For single-temporal encoders, the list's\n",
        "            elements are of shape (B, embed_dim, H', W'). For multi-temporal encoders, the list's elements are of shape\n",
        "            (B, C', T, H', W') with T the number of time steps if the encoder does not have any time-merging strategy,\n",
        "            else (B, C', H', W') if the encoder has a time-merging strategy (where C'==self.output_dim).\n",
        "        \"\"\"\n",
        "        x = image['optical']\n",
        "        outputs = []\n",
        "        # Forward pass through the model\n",
        "        for idx, layer in enumerate(self.backbone):\n",
        "            x = layer(x)\n",
        "            if idx in self.output_layers:\n",
        "                outputs.append(x)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOPK1uLHv0Gv"
      },
      "source": [
        "Some other practical hints/reccomendetions:\n",
        " - name your _model_ file: ***fgmae_encoder.py*** and put it in _model/encoders_\n",
        " - name your _config_ file: ***fgmae.yaml*** and put it in _configs/encoder_\n",
        " - HINT! Get inspired by SSL4EO_MAE files to follow the structure of the files. The  structure is the same! Also this [link](https://github.com/zhu-xlab/FGMAE/blob/main/src/transfer_classification/models/mae/models_vit.py) can be useful!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvkiqQ-vwNHo"
      },
      "source": [
        "Now you are ready to run the code on your newly added model. Run the following command line!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBFQm8QTwJFQ"
      },
      "outputs": [],
      "source": [
        "# Use torchrun to launch training\n",
        "# Dataset: toyflair (already added)\n",
        "# Encoder: FG-MAE model\n",
        "# Decoder: UPerNet\n",
        "# Preprocessing: default settings\n",
        "# Criterion: cross entropy loss\n",
        "# Task: segmentation\n",
        "!torchrun --nnodes=1 --nproc_per_node=1 pangaea/run.py \\\n",
        "  --config-name=train \\\n",
        "  dataset=toyflair \\\n",
        "  encoder=fgmae \\\n",
        "  decoder=seg_upernet \\\n",
        "  preprocessing=seg_default \\\n",
        "  criterion=cross_entropy \\\n",
        "  task=segmentation \\\n",
        "  use_wandb=True \\\n",
        "  task.trainer.n_epochs=40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dt511MyDvCIl"
      },
      "outputs": [],
      "source": [
        "!torchrun pangaea/run.py --config-name=test ckpt_dir=/insert/your/results/directory"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
